---
title: "Scoping Review Protocol: Statistical Models for Longitudinal Data"
date: "`r Sys.Date()`"
author: "Ariel I. Mundo Ortiz"
affiliation: "Université de Montréal, Montreal, QC, Canada"
format:
  pdf:
    keep-tex: true
    documentclass: article
    toc: true
    number-sections: true
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - heightrounded
    include-in-header: latex_docs/preamble.sty
    csl: references/american-medical-association.csl
    bibliography: references/refs.bib
---

# Background

Longitudinal studies are frequently used in the health sciences (biomedical research, epidemiology, public health, among others) as they allow to examine how the temporal effect of a treatment or an intervention, in contrast to a cross-sectional study, which only allows to examine the effect of the intervention at a single time point.  When compared to cross-sectional studies, longitudinal studies allow for increased statistical power and more cost efficient strategies [@edwards2000;@zeger1992]. However, the statistical analysis of longitudinal data requires to take into consideration factors such as data missingness, correlation, and non-linear trends, which do not occur on cross-sectional data [@caruana2015;@mundo2022a]. In other words, there is an "analytic cost" associated with the increased complexity of longitudinal data [@zeger1992].

This additional layer of complexity has led to a problem with the misspecification of the statistical models used to analyze longitudinal data (the use of a statistical model that is not coherent with the data) which has been reported in the past in the health sciences [@thiese2015]. Such problem can be partially explained by the fact that researchers have a tendency to use the same statistical analyses, methods, and tests from other papers without having a clear understanding of the limitations, assumptions, and applicability of the model in each situation [@ercan2007;@thiese2015]. For example, in a landmark study Liu et al. showed that in a subset of papers in the biomedical sciences, the most popular model used to analyze longitudinal data was ANOVA (an approach that fails to take into account the correlation between measures over time), and that only 18% of the studies analyzed used models intended for longitudinal analysis while checking that the assumptions of the model were satisfied by the data [@liu2010]. 

Historically, the repeated measures analysis of variance (rm-ANOVA) has been the preferred method in the health sciences to analyze longitudinal data, despite the fact that frequently, the data does not satisfy assumptions required for its use [@mundo2022a]. On the other hand, the last 30 years have seen incredible progress in the field of Statistics with the development of statistical models for longitudinal data that overcome the limitations of rm-ANOVA. Such modern statistical models include linear mixed models, generalized additive models, Bayesian models, and generalized estimating equations among others [@pinheiro2000;@jiang2021;@hastie2017;@rosa2004;@ballinger2004]. However, the adoption of these modern statistical techniques has been slow within the health sciences, as showcased by Gueorguieva et al., who showed that by 2001, only 30% of clinical trials reported in the _Archives of General Psychiatry_ used linear mixed models to analyze their results, and that rm-ANOVA continued to be the preferred method of analysis in most cases [@gueorguieva2004]. By comparison, McCullagh and Nelder wrote a seminal book on the generalized linear model (GLM) by 1989 [@mccullagh2019], and Breslow and Clayton reported work on the extension of the GLM framework to the mixed model case by 1993 [@breslow1993].

However, progress has been made during the last decade as statistical models such as generalized additive models, generalized estimating equations, and linear mixed models have been used by different groups to analyze longitudinal data in the health sciences [@mundo2022b;@wang2014;@tian2020;@sevik2017]. Despite this, the current status in the adoption of these modern statistical methods by the field at large remains unknown. Because the use of appropriate statistical tools is a core component of research reproducibility [@gosselin2020;@lang2015], there is a need to better understand the current status of statistical practices for longitudinal data in the health sciences, and to identify the ongoing issues in the adoption of modern statistical models for longitudinal data.

To answer these questions, in this study we surveyed the statistical methods used in papers dealing with longitudinal data in health sciences over the last 20 years, in order to gain a better understanding of: 1) the trends in adoption of modern statistical methods, 2) identify the most frequent pitfalls in the analsys of longitudinal data, and 3) provide a rationale for situations where these methods are still not widely adopted. 

#  Objective

This study aims to summarize the different statistical models for longitudinal data that are used in the health sciences, identify the extent of the adoption of modern statistical methods in the field, and determine if in each case, model assumptions are checked by researchers to ensure congruency between the data and the model.


# Review Question

Summarize the statistical methods used to analyze longitudinal data in the health sciences to identify which methods are most commonly used, the applicability of such methods in the context of each study, and gaps that might exist that prevent the adoption of modern statistical methods that can be better suited to analyze the data. Additionally, identify if studies check for model assumptions, and how this in turn impacts the reported results.

# Databases

- PubMed
- Web of Science

# Search Terms

# Criteria

## Inclusion Criteria

- methods paper see new methods developed 

- application

## Exclusion Criteria

# Additional Resources

# Comparison (?)

# Data Extraction

# Data Synthesis Strategy

# References

::: {#refs}
:::